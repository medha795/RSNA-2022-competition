{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings \nwarnings.filterwarnings('ignore')\n\nfrom matplotlib.patches import Rectangle \nimport os \nimport re \nimport random \nimport matplotlib.pyplot as plt \nimport plotly \nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nimport plotly.express as px \nfrom pydicom import dcmread \nfrom tqdm import tqdm \nimport multiprocessing as mp \nimport seaborn as sns \nimport datetime\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-03T20:02:11.153930Z","iopub.execute_input":"2022-10-03T20:02:11.155668Z","iopub.status.idle":"2022-10-03T20:02:12.563150Z","shell.execute_reply.started":"2022-10-03T20:02:11.155553Z","shell.execute_reply":"2022-10-03T20:02:12.561757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/rsna-2022-cervical-spine-fracture-detection\"\n\ntrain_dataframe = pd.read_csv(os.path.join(PATH, 'train.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:12.569839Z","iopub.execute_input":"2022-10-03T20:02:12.570587Z","iopub.status.idle":"2022-10-03T20:02:12.586489Z","shell.execute_reply.started":"2022-10-03T20:02:12.570535Z","shell.execute_reply":"2022-10-03T20:02:12.584823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:12.588219Z","iopub.execute_input":"2022-10-03T20:02:12.588582Z","iopub.status.idle":"2022-10-03T20:02:12.613007Z","shell.execute_reply.started":"2022-10-03T20:02:12.588550Z","shell.execute_reply":"2022-10-03T20:02:12.611419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe.info()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:12.615940Z","iopub.execute_input":"2022-10-03T20:02:12.616438Z","iopub.status.idle":"2022-10-03T20:02:12.633275Z","shell.execute_reply.started":"2022-10-03T20:02:12.616398Z","shell.execute_reply":"2022-10-03T20:02:12.632081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:12.634677Z","iopub.execute_input":"2022-10-03T20:02:12.635172Z","iopub.status.idle":"2022-10-03T20:02:12.649403Z","shell.execute_reply.started":"2022-10-03T20:02:12.635133Z","shell.execute_reply":"2022-10-03T20:02:12.648323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:12.650879Z","iopub.execute_input":"2022-10-03T20:02:12.651291Z","iopub.status.idle":"2022-10-03T20:02:12.660764Z","shell.execute_reply.started":"2022-10-03T20:02:12.651253Z","shell.execute_reply":"2022-10-03T20:02:12.659545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataframe['nb_scans'] = train_dataframe['StudyInstanceUID'].apply(lambda x: len(os.listdir(f'../input/rsna-2022-cervical-spine-fracture-detection/train_images/{x}')))\ntrain_dataframe['nb_fractures'] = train_dataframe[['C1','C2', 'C3', 'C4', 'C5', 'C6', 'C7']].sum(axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:12.662023Z","iopub.execute_input":"2022-10-03T20:02:12.662463Z","iopub.status.idle":"2022-10-03T20:02:41.940063Z","shell.execute_reply.started":"2022-10-03T20:02:12.662423Z","shell.execute_reply":"2022-10-03T20:02:41.938801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.box(train_dataframe, y = \"nb_scans\", points = \"all\", title = 'Nb scans per patient', color_discrete_sequence = [\"goldenrod\"])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:41.941712Z","iopub.execute_input":"2022-10-03T20:02:41.942159Z","iopub.status.idle":"2022-10-03T20:02:42.460668Z","shell.execute_reply.started":"2022-10-03T20:02:41.942109Z","shell.execute_reply":"2022-10-03T20:02:42.459006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_c = {}\nfor i in range (1,7): \n    dict_c[f'C{i}'] = train_dataframe.loc[train_dataframe[f'C{i}'] == 1].shape[0]\n    \nx = list(dict_c.keys())\ny = list(dict_c.values())\n\nmax_index = np.argmax(list(dict_c.values()))\ncolors = ['lightblue' ,] * 7 \ncolors[max_index] = 'goldenrod'\n\nfig = go.Figure(\n    data = [\n        go.Bar(\n        x = x, \n        y = y, \n        marker_color = colors)\n    ])\nfig.update_layout(title_text = 'Fractured vertebrae location counts')","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.462383Z","iopub.execute_input":"2022-10-03T20:02:42.462917Z","iopub.status.idle":"2022-10-03T20:02:42.491638Z","shell.execute_reply.started":"2022-10-03T20:02:42.462864Z","shell.execute_reply":"2022-10-03T20:02:42.490245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['lightblue',] * 6 \ncolors[0] = 'goldenrod'\n\ndict_nb_fractures = dict(train_dataframe.loc[train_dataframe['nb_fractures'] != 0, 'nb_fractures'].value_counts())\n\nx = list(dict_nb_fractures.keys())\ny = list(dict_nb_fractures.values())\n\nfig = go.Figure(data = [go.Bar ( x = x, y = y, marker_color = colors)])\n\nfig.update_layout(title_text = 'Fracture counts distribution')","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.493809Z","iopub.execute_input":"2022-10-03T20:02:42.494217Z","iopub.status.idle":"2022-10-03T20:02:42.514774Z","shell.execute_reply.started":"2022-10-03T20:02:42.494181Z","shell.execute_reply":"2022-10-03T20:02:42.513553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y0 = train_dataframe.loc[train_dataframe[\"nb_fractures\"] == 1, 'nb_scans']\ny1 = train_dataframe.loc[train_dataframe[\"nb_fractures\"] == 2, 'nb_scans']\ny2 = train_dataframe.loc[train_dataframe[\"nb_fractures\"] == 3, 'nb_scans']\ny3 = train_dataframe.loc[train_dataframe[\"nb_fractures\"] == 4, 'nb_scans']\ny4 = train_dataframe.loc[train_dataframe[\"nb_fractures\"] == 5, 'nb_scans']\ny5 = train_dataframe.loc[train_dataframe[\"nb_fractures\"] == 6, 'nb_scans']\n\nfig = go.Figure()\nfig.add_trace(go.Box(y=y0, name = \"1\", marker_color = 'lightblue'))\nfig.add_trace(go.Box(y=y1, name = \"2\", marker_color = 'lightblue'))\nfig.add_trace(go.Box(y=y2, name = \"3\", marker_color = 'goldenrod'))\nfig.add_trace(go.Box(y=y3, name = \"4\", marker_color = 'lightblue'))\nfig.add_trace(go.Box(y=y4, name = \"5\", marker_color = 'goldenrod'))\nfig.add_trace(go.Box(y=y5, name = \"6\", marker_color = 'lightblue'))\n\nfig.update_layout(title_text = 'Scan counts per nb fracture', showlegend = False)\nfig.update_xaxes(title = 'At least')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.518590Z","iopub.execute_input":"2022-10-03T20:02:42.519004Z","iopub.status.idle":"2022-10-03T20:02:42.550426Z","shell.execute_reply.started":"2022-10-03T20:02:42.518964Z","shell.execute_reply":"2022-10-03T20:02:42.549231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# READ DICOM FILES","metadata":{}},{"cell_type":"markdown","source":"**What is a DICOM file?**\n\nA DICOM files is an image saved in Digital Imaging and Communications in Medicine format. It contains an image from a medical scan, such as an ultrasound or an MRI. DICOM files may also include identification data for patients to link the image to a specific individual. ","metadata":{}},{"cell_type":"code","source":"ds = dcmread(os.path.join(PATH, 'train_images', '1.2.826.0.1.3680043.10001/1.dcm'))\nds","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.552080Z","iopub.execute_input":"2022-10-03T20:02:42.552457Z","iopub.status.idle":"2022-10-03T20:02:42.582096Z","shell.execute_reply.started":"2022-10-03T20:02:42.552421Z","shell.execute_reply":"2022-10-03T20:02:42.580811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXTRACTING METADATA FROM THE DICOM FILES","metadata":{}},{"cell_type":"code","source":"def extract_file(file_path):\n    \n    ds = dcmread(file_path)\n    image_id = file_path.split(sep=\"/\")[-2]\n\n    observation_dict = {}\n    observation_dict['image_id'] = image_id\n    \n    file_meta_keys = list(ds.file_meta._dict.keys())\n    remaining_meta_keys = list(ds._dict.keys())\n    \n    for key in file_meta_keys:\n        observation_dict[str(key)] = str(ds.file_meta[key].value)\n        \n    # Not taking into account pixel value\n    for key in remaining_meta_keys:\n        if key != (0x7fe0, 0x0010):\n            observation_dict[str(key)] = str(ds[key].value)\n        \n    return observation_dict","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.587988Z","iopub.execute_input":"2022-10-03T20:02:42.588429Z","iopub.status.idle":"2022-10-03T20:02:42.597177Z","shell.execute_reply.started":"2022-10-03T20:02:42.588389Z","shell.execute_reply":"2022-10-03T20:02:42.595728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_file('../input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.10001/1.dcm')","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.598982Z","iopub.execute_input":"2022-10-03T20:02:42.599418Z","iopub.status.idle":"2022-10-03T20:02:42.617245Z","shell.execute_reply.started":"2022-10-03T20:02:42.599378Z","shell.execute_reply":"2022-10-03T20:02:42.615558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapper_dict = { \n    'image_id' : 'image_id', \n     '(0002, 0001)' : \"File Meta Information Version\", \n     '(0002, 0002)' : \"Media Storage SOP Class UID\", \n     '(0002, 0003)' : \"Media Storage SOP Instance UID\", \n     '(0002, 0010)' : \"Transfer Syntax UID\", \n     '(0002, 0012)' : \"Implementation Class UID\", \n     '(0002, 0013)' : \"Implementation Version Name\", \n\n     '(0008, 0018)' : \"SOPInstanceUID\", \n     '(0008, 0023)' : \"Date of Creation\", \n     '(0008, 0033)' : \"Time of Creation\", \n\n     '(0010, 0010)' : \"Patient Name\", \n     '(0010, 0020)' : \"Patient ID\", \n     \n     '(0018, 0050)' : \"Slice Thickness\", \n     \n     '(0020, 000d)' : \"Study Instance UID\", \n     '(0020, 000e)' : \"Series Instance UID\", \n     '(0020, 0013)' : \"Instance Number\", \n     '(0020, 0032)' : \"Image Position (Patient)\", \n     '(0020, 0037)' : \"Image Orientation (Patient)\", \n\n     '(0028, 0002)' : \"Samples per Pixel\", \n     '(0028, 0004)' : \"Photometric Interpretation\", \n     '(0028, 0010)' : \"Rows\", \n     '(0028, 0011)' : \"Columns\", \n     '(0028, 0030)' : \"Pixel Spacing\", \n     '(0028, 0100)' : \"Bits Allocated\", \n     '(0028, 0101)' : \"Bits Stored\", \n     '(0028, 0102)' : \"High Bit\", \n     '(0028, 0103)' : \"Pixel Representation\", \n     '(0028, 1050)' : \"Window Center\", \n     '(0028, 1051)' : \"Window Width\", \n     '(0028, 1052)' : \"Rescale Intercept\", \n     '(0028, 1053)' : \"Rescale Slope\"} ","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.618665Z","iopub.execute_input":"2022-10-03T20:02:42.619195Z","iopub.status.idle":"2022-10-03T20:02:42.627995Z","shell.execute_reply.started":"2022-10-03T20:02:42.619156Z","shell.execute_reply":"2022-10-03T20:02:42.626627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def meta_information_one_folder(folder): \n    \n    folder_filenames = os.listdir(os.path.join(PATH, folder))\n    one_obs = extract_file(os.path.join(PATH, folder, folder_filenames[0]))\n    metadata = pd.DataFrame(columns = one_obs.keys())\n    \n    print(f'Extracting metadata from folder {folder}')\n    for filename in tqdm(folder_filenames): \n        one_obs = extract_file(os.path.join(PATH, folder, filename))\n        metadata = metadata.append(one_obs, ignore_index = True)\n        \n    metadata.columns = metadata.columns.map(mapper_dict)\n    metadata.to_csv(f\"dicom_metadata.csv\", index = False)\n    \n    return metadata","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.629964Z","iopub.execute_input":"2022-10-03T20:02:42.630917Z","iopub.status.idle":"2022-10-03T20:02:42.647145Z","shell.execute_reply.started":"2022-10-03T20:02:42.630866Z","shell.execute_reply":"2022-10-03T20:02:42.645930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = meta_information_one_folder('train_images/1.2.826.0.1.3680043.10001')","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:42.648937Z","iopub.execute_input":"2022-10-03T20:02:42.649318Z","iopub.status.idle":"2022-10-03T20:02:48.833251Z","shell.execute_reply.started":"2022-10-03T20:02:42.649282Z","shell.execute_reply":"2022-10-03T20:02:48.831830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in metadata.columns: \n    if len(set(metadata[column])) != 1: \n        print(column)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:48.835095Z","iopub.execute_input":"2022-10-03T20:02:48.836539Z","iopub.status.idle":"2022-10-03T20:02:48.850255Z","shell.execute_reply.started":"2022-10-03T20:02:48.836485Z","shell.execute_reply":"2022-10-03T20:02:48.848964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESSING METADATA","metadata":{}},{"cell_type":"code","source":"metadata['Date of Creation'] = metadata['Time of Creation'].apply(lambda x: datetime.datetime.fromtimestamp(eval(x)).strftime('%Y-%m-%d %H:%M:%S'))\nmetadata[['Media Storage SOP Instance UID', 'SOPInstanceUID', 'Time of Creation', 'Date of Creation', 'Instance Number', 'Image Position (Patient)']].head()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:48.852606Z","iopub.execute_input":"2022-10-03T20:02:48.853844Z","iopub.status.idle":"2022-10-03T20:02:48.879105Z","shell.execute_reply.started":"2022-10-03T20:02:48.853788Z","shell.execute_reply":"2022-10-03T20:02:48.877604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SOME OBSERVATIONS","metadata":{}},{"cell_type":"code","source":"def get_random_files_from_patient(path):\n   \n    \n    return random.sample(os.listdir(path), 9)\n\n\ndef rescale_image(dicom_file):\n   \n    \n    image = dicom_file.pixel_array.flatten()\n    rescaled_image = image * dicom_file.RescaleSlope + dicom_file.RescaleIntercept\n    \n    return image, rescaled_image\n\n\ndef display_images(files_list, graph_indexes = np.arange(9)):\n   \n    \n   \n    fig, axs = plt.subplots(3,3, figsize=(20,12))\n    for idx, file in enumerate(files_list):\n        \n        full_path = os.path.join('../input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.10001', file)\n        ds = dcmread(full_path)\n\n        axs[idx//3, 0].imshow(ds.pixel_array, cmap=plt.get_cmap('gray'))   \n        axs[idx//3, 0].axis(\"off\")\n        \n        image, rescaled_image = rescale_image(ds)\n        \n        sns.distplot(image.flatten(), ax=axs[idx//3, 1]);\n        sns.distplot(rescaled_image.flatten(), ax=axs[idx//3, 2])\n        axs[idx//3, 1].set_title(\"Raw pixel array distributions\")\n        axs[idx//3, 2].set_title(\"HU unit distributions\");    \n        \n        \n  \n    plt.subplots_adjust(bottom = 0.001)\n    plt.subplots_adjust(top = 0.99)\n    \n  \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:48.880765Z","iopub.execute_input":"2022-10-03T20:02:48.881492Z","iopub.status.idle":"2022-10-03T20:02:48.894953Z","shell.execute_reply.started":"2022-10-03T20:02:48.881438Z","shell.execute_reply":"2022-10-03T20:02:48.893023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_to_display = get_random_files_from_patient('../input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.10001')\ndisplay_images(files_to_display)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:02:48.896642Z","iopub.execute_input":"2022-10-03T20:02:48.897466Z","iopub.status.idle":"2022-10-03T20:03:08.729816Z","shell.execute_reply.started":"2022-10-03T20:02:48.897422Z","shell.execute_reply":"2022-10-03T20:03:08.728334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BOUNDING BOXES ","metadata":{}},{"cell_type":"code","source":"bb_train = pd.read_csv('../input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv')\nbb_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:08.731325Z","iopub.execute_input":"2022-10-03T20:03:08.731772Z","iopub.status.idle":"2022-10-03T20:03:08.780326Z","shell.execute_reply.started":"2022-10-03T20:03:08.731716Z","shell.execute_reply":"2022-10-03T20:03:08.779094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bb_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:08.782032Z","iopub.execute_input":"2022-10-03T20:03:08.782415Z","iopub.status.idle":"2022-10-03T20:03:08.789631Z","shell.execute_reply.started":"2022-10-03T20:03:08.782379Z","shell.execute_reply":"2022-10-03T20:03:08.788217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bb_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:08.791666Z","iopub.execute_input":"2022-10-03T20:03:08.792085Z","iopub.status.idle":"2022-10-03T20:03:08.805954Z","shell.execute_reply.started":"2022-10-03T20:03:08.792032Z","shell.execute_reply":"2022-10-03T20:03:08.804459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install monai\n","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:08.807366Z","iopub.execute_input":"2022-10-03T20:03:08.807883Z","iopub.status.idle":"2022-10-03T20:03:20.288099Z","shell.execute_reply.started":"2022-10-03T20:03:08.807808Z","shell.execute_reply":"2022-10-03T20:03:20.286475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qU \"python_gdcm\" pydicom pylibjpeg","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:20.290622Z","iopub.execute_input":"2022-10-03T20:03:20.291240Z","iopub.status.idle":"2022-10-03T20:03:32.734441Z","shell.execute_reply.started":"2022-10-03T20:03:20.291173Z","shell.execute_reply":"2022-10-03T20:03:32.732849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nfrom monai.transforms import LoadImaged, EnsureChannelFirstd, ResampleToMatchd, Orientationd, Compose\nimport monai\nimport numpy as np\nfrom tqdm import tqdm\nimport multiprocessing\nfrom ipywidgets import interactive, widgets, fixed\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:32.736388Z","iopub.execute_input":"2022-10-03T20:03:32.736845Z","iopub.status.idle":"2022-10-03T20:03:35.189901Z","shell.execute_reply.started":"2022-10-03T20:03:32.736797Z","shell.execute_reply":"2022-10-03T20:03:35.188262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dir = \"../input/rsna-2022-cervical-spine-fracture-detection/train_images/\"\nmask_dir = \"../input/rsna-2022-cervical-spine-fracture-detection/segmentations/\"\nmask_list = os.listdir(mask_dir)\nimage_list = os.listdir(image_dir)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:35.192144Z","iopub.execute_input":"2022-10-03T20:03:35.193375Z","iopub.status.idle":"2022-10-03T20:03:35.203055Z","shell.execute_reply.started":"2022-10-03T20:03:35.193306Z","shell.execute_reply":"2022-10-03T20:03:35.201769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = Compose(\n    [\n        LoadImaged(reader=(\"PydicomReader\", \"nibabelreader\"), keys=[\"image\", \"seg\"]),\n        EnsureChannelFirstd(keys=[\"image\", \"seg\"]),\n        # unify the orientations of image and mask\n        Orientationd(keys=[\"image\", \"seg\"], axcodes=\"RAS\"),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:35.204752Z","iopub.execute_input":"2022-10-03T20:03:35.205206Z","iopub.status.idle":"2022-10-03T20:03:35.217428Z","shell.execute_reply.started":"2022-10-03T20:03:35.205144Z","shell.execute_reply":"2022-10-03T20:03:35.216064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_animation(img, seg, seg_rev=False, fps=10):\n\n    images = img\n    segs = seg\n    \n    if seg_rev:\n        segs = segs[::-1]\n    ims_sgs = [np.concatenate([images[i], segs[i]], axis=1) for i in range(len(images))]\n    \n  \n    animation_arr = np.stack(ims_sgs, axis=0)\n    \n    del images, ims_sgs\n    gc.collect()\n    \n  \n    fig = plt.figure(figsize=(5,5), dpi=160)  \n    im = plt.imshow(animation_arr[0], cmap='bone')\n    plt.axis('off')\n    \n  \n    def animate_func(i):\n        im.set_array(animation_arr[i])\n        return [im]\n    plt.close()\n    \n    anim = animation.FuncAnimation(fig, animate_func, frames = animation_arr.shape[0], interval = 1000//fps)\n    \n    return anim","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:35.219008Z","iopub.execute_input":"2022-10-03T20:03:35.219386Z","iopub.status.idle":"2022-10-03T20:03:35.232410Z","shell.execute_reply.started":"2022-10-03T20:03:35.219351Z","shell.execute_reply":"2022-10-03T20:03:35.231015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_sample = \"1.2.826.0.1.3680043.25704\"\nmask_sample = f\"{img_sample}.nii\"\n\ndata = {\"image\": os.path.join(image_dir, img_sample), \"seg\": os.path.join(mask_dir, mask_sample)}\noutput = transform(data)\n\nimg = output[\"image\"].numpy().transpose([0, 3, 2, 1])[0]\nseg = output[\"seg\"].numpy().transpose([0, 3, 2, 1])[0]\n\nimg = (img-np.min(img))/(np.max(img)-np.min(img)+1e-6)\nimg = (img*255).astype(np.uint8)\n\nseg = np.where(seg>0, 255, 0).astype(np.uint8)\n\n\ncreate_animation(img, seg, fps=30)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:03:35.234100Z","iopub.execute_input":"2022-10-03T20:03:35.234591Z","iopub.status.idle":"2022-10-03T20:04:16.747282Z","shell.execute_reply.started":"2022-10-03T20:03:35.234532Z","shell.execute_reply":"2022-10-03T20:04:16.745185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_sample = \"1.2.826.0.1.3680043.1363\"\nmask_sample = f\"{img_sample}.nii\"\n\ndata = {\"image\": os.path.join(image_dir, img_sample), \"seg\": os.path.join(mask_dir, mask_sample)}\noutput = transform(data)\n\nimg = output[\"image\"].numpy().transpose([0, 3, 2, 1])[0]\nseg = output[\"seg\"].numpy().transpose([0, 3, 2, 1])[0]\n\nimg = (img-np.min(img))/(np.max(img)-np.min(img)+1e-6)\nimg = (img*255).astype(np.uint8)\n\nseg = np.where(seg>0, 255, 0).astype(np.uint8)\n\n\ncreate_animation(img, seg, fps=30)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:04:16.749070Z","iopub.execute_input":"2022-10-03T20:04:16.749505Z","iopub.status.idle":"2022-10-03T20:04:52.636636Z","shell.execute_reply.started":"2022-10-03T20:04:16.749466Z","shell.execute_reply":"2022-10-03T20:04:52.635190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q monai\n!pip install -q git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:04:52.638297Z","iopub.execute_input":"2022-10-03T20:04:52.638690Z","iopub.status.idle":"2022-10-03T20:05:18.532234Z","shell.execute_reply.started":"2022-10-03T20:04:52.638652Z","shell.execute_reply":"2022-10-03T20:05:18.531104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nimport re \nimport gc \nimport cv2 \nimport wandb \nfrom PIL import Image \nimport random \nimport math \nimport shutil \nfrom glob import glob \nfrom tqdm import tqdm \nfrom pprint import pprint \nfrom time import time \nimport warnings \nimport pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib as mpl \nimport matplotlib.patches as patches \nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg \nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage \nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap \nfrom matplotlib.patches import Rectangle \nfrom IPython.display import display_html \nplt.rcParams.update({'font.size' : 16})\n\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"WANDB_SILENT\"] = \"true\"\nCONFIG = {'competition' : 'RSNA_SpineFructure', '_wandb_kernel' : 'aot'}\n\nclass clr: \n    S = '\\033[1m' + '\\033[94m'\n    E = '\\033[0m'\n    \nmy_colors = [\"#5EAFD9\", \"#449DD1\", \"#3977BB\", \n             \"#2D51A5\", \"#5C4C8F\", \"#8B4679\", \n             \"#C53D4C\", \"#E23836\", \"#FF4633\", \"#FF5746\"]\nCMAP1 = ListedColormap(my_colors)\n\nprint(clr.S+\"Notebook Color Schemes:\"+clr.E)\nsns.palplot(sns.color_palette(my_colors))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:05:18.534256Z","iopub.execute_input":"2022-10-03T20:05:18.534811Z","iopub.status.idle":"2022-10-03T20:05:18.649781Z","shell.execute_reply.started":"2022-10-03T20:05:18.534748Z","shell.execute_reply":"2022-10-03T20:05:18.648206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \nfrom torch.utils.data import TensorDataset, DataLoader, Dataset \nimport torch.nn as nn \nimport torch.nn.functional as F \nimport torch.optim as optim \nfrom torch.optim import lr_scheduler \nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler \nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR \nimport torchvision \nimport torchvision.transforms as transforms \nfrom warmup_scheduler import GradualWarmupScheduler \nimport albumentations \n\nfrom sklearn.model_selection import GroupKFold, train_test_split, StratifiedKFold \nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix \n\nfrom monai.transforms import Randomizable, apply_transform \nfrom monai.transforms import Compose, Resize, ScaleIntensity, ToTensor, RandAffine \nfrom monai.networks.nets import densenet ","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:05:18.655687Z","iopub.execute_input":"2022-10-03T20:05:18.659802Z","iopub.status.idle":"2022-10-03T20:05:18.883910Z","shell.execute_reply.started":"2022-10-03T20:05:18.659709Z","shell.execute_reply":"2022-10-03T20:05:18.882145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient \nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")\n\n! wandb login $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2022-10-03T20:05:18.885773Z","iopub.execute_input":"2022-10-03T20:05:18.886252Z","iopub.status.idle":"2022-10-03T20:05:22.249571Z","shell.execute_reply.started":"2022-10-03T20:05:18.886201Z","shell.execute_reply":"2022-10-03T20:05:22.247952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0): \n    \n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    \ndef show_values_on_bars(axs, h_v = \"v\", space = 0.4): \n    def _show_on_single_plot(ax): \n        if h_v == \"v\": \n            for p in ax.patches: \n                _x = p.get_x() + p.get_width() / 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, format(value, ','), ha = \"center\")\n        elif h_v == \"h\": \n            for p in ax.patches: \n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_x() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, format(value, ','), ha = \"left\")\n                \n    if isinstance(axs, np.ndarray): \n        for idx, ax in np.ndenumerate(axs): \n            _show_on_single_plot(ax)\n        else: \n            _show_on_single_plot(axs)\n            \ndef atoi(text): \n    return int(text) if text.isdigit() else text \n\ndef natural_keys(text): \n    \n    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n\ndef save_dataset_artifact(run_name, artifact_name, path, data_type = \"dataset\"): \n    \n    run = wandb.init(project = 'RSNA_SpineFructure', \n                     name = run_name, \n                     config = CONFIG)\n    artifact = wandb.Artifact(name = artifact_name, type = data_type)\n    artifact.add_file(path)\n    \n    wandb.log_artifact(artifact)\n    wandb.finish()\n    print(\"Artifact has been saved successfully.\")\n    \ndef create_wandb_plot(x_data = None, y_data = None, x_name = None, y_name = None, title = None, log = None, plot = \"line\"): \n    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n    table = wandb.Table(data = data, columns = [x_name, y_name])\n    \n    if plot == \"line\": \n        wandb.log({log : wandb.plot.line(table, x_name, y_name, title = title)})\n    elif plot == \"bar\": \n        wandb.log({log : wandb.plot.bar(table, x_name, y_name, title = title)})\n    elif plot == \"scatter\": \n        wandb.log({log : wandb.plot.scatter(table, x_name, y_name, title = title)})\n\n        \ndef create_wandb_hist(x_data = None, x_name = None, title = None, log = None): \n    \n    data = [[x] for x in x_data]\n    table = wandb.Table(data = data, columns = [x_name])\n    wandb.log({log : wandb.plot.histogram(table, x_name, title = title)})","metadata":{"execution":{"iopub.status.busy":"2022-10-03T21:15:53.015392Z","iopub.execute_input":"2022-10-03T21:15:53.015914Z","iopub.status.idle":"2022-10-03T21:15:53.036831Z","shell.execute_reply.started":"2022-10-03T21:15:53.015864Z","shell.execute_reply":"2022-10-03T21:15:53.035360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T21:15:56.410220Z","iopub.execute_input":"2022-10-03T21:15:56.410656Z","iopub.status.idle":"2022-10-03T21:15:56.417383Z","shell.execute_reply.started":"2022-10-03T21:15:56.410617Z","shell.execute_reply":"2022-10-03T21:15:56.416092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(clr.S+\"Device:\"+clr.E, DEVICE)\n\nDF_SIZE = 0.03\nN_SPLITS = 5\nKERNEL_TYPE = 'densenet121_baseline'\nIMG_RESIZE = 100 \nSTACK_RESIZE = 50 \nuse_amp = False \nNUM_WORKERS = 1 \nBATCH_SIZE = 2 \nLR = 0.05 \nOUT_DIM = 8 \nEPOCHS = 2 ","metadata":{"execution":{"iopub.status.busy":"2022-10-03T21:30:59.967138Z","iopub.execute_input":"2022-10-03T21:30:59.967629Z","iopub.status.idle":"2022-10-03T21:30:59.976847Z","shell.execute_reply.started":"2022-10-03T21:30:59.967592Z","shell.execute_reply":"2022-10-03T21:30:59.975626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = ['C1', 'C2', 'C3', \n               'C4', 'C5', 'C6', 'C7', \n               'patient_overall']","metadata":{"execution":{"iopub.status.busy":"2022-10-03T21:33:53.081710Z","iopub.execute_input":"2022-10-03T21:33:53.082217Z","iopub.status.idle":"2022-10-03T21:33:53.088305Z","shell.execute_reply.started":"2022-10-03T21:33:53.082180Z","shell.execute_reply":"2022-10-03T21:33:53.087081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"competition_weights = { \n     '-' : torch.tensor([1,1,1,1,1,1,1,7], dtype = torch.float, device = DEVICE), \n     '+' : torch.tensor([2,2,2,2,2,2,2,14], dtype = torch.float, device = DEVICE)}","metadata":{"execution":{"iopub.status.busy":"2022-10-03T21:44:26.063822Z","iopub.execute_input":"2022-10-03T21:44:26.064328Z","iopub.status.idle":"2022-10-03T21:44:26.072128Z","shell.execute_reply.started":"2022-10-03T21:44:26.064291Z","shell.execute_reply":"2022-10-03T21:44:26.070710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = torch.tensor([[0.2221, 0.1037, 0.0739, 0.1112, 0.1026, 0.0902, 0.1597, 0.1365], \n                       [0.1702, 0.0952, 0.0815, 0.1262, 0.1185, 0.1097, 0.1675, 0.1312]], device = DEVICE)\nprint(clr.S+\"Prediction:\"+clr.E, \"\\n\", logits)\n\ntargets = torch.tensor([[0., 0., 0. , 0. , 0. , 0. , 0. , 0.], \n                        [1. , 0. , 0. , 0. , 0. , 0. , 0. , 1.]], device = DEVICE)\nprint(clr.S+\"Target:\"+clr.E, \"\\n\", targets)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T22:14:39.718401Z","iopub.execute_input":"2022-10-03T22:14:39.718937Z","iopub.status.idle":"2022-10-03T22:14:39.731877Z","shell.execute_reply.started":"2022-10-03T22:14:39.718893Z","shell.execute_reply":"2022-10-03T22:14:39.730620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = targets * competition_weights ['+'] + (1 - targets) + competition_weights['-']\nprint(clr.S+\"Weights:\"+clr.E, \"\\n\", weights)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T22:16:09.431957Z","iopub.execute_input":"2022-10-03T22:16:09.433078Z","iopub.status.idle":"2022-10-03T22:16:09.447511Z","shell.execute_reply.started":"2022-10-03T22:16:09.433028Z","shell.execute_reply":"2022-10-03T22:16:09.446188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L = torch.zeros(targets.shape, device=DEVICE)\n\nw = weights\ny = targets\np = logits\n\nfor i in range(L.shape[0]):\n    for j in range(L.shape[1]):\n        L[i, j] = -w[i, j] * (\n            y[i, j] * math.log(p[i, j]) +\n            (1 - y[i, j]) * math.log(1 - p[i, j]))\n        \nprint(clr.S+\"LOSSES:\"+clr.E, \"\\n\", L)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T22:20:16.998038Z","iopub.execute_input":"2022-10-03T22:20:16.998832Z","iopub.status.idle":"2022-10-03T22:20:17.010091Z","shell.execute_reply.started":"2022-10-03T22:20:16.998787Z","shell.execute_reply":"2022-10-03T22:20:17.008814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Exams_Loss = torch.div(torch.sum(L, dim = 1), torch.sum(w, dim = 1))\nprint(clr.S+\"Exam Losses:\"+clr.E, \"\\n\", Exams_Loss)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T22:22:15.516378Z","iopub.execute_input":"2022-10-03T22:22:15.516855Z","iopub.status.idle":"2022-10-03T22:22:15.525795Z","shell.execute_reply.started":"2022-10-03T22:22:15.516814Z","shell.execute_reply":"2022-10-03T22:22:15.524027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_custom_loss(logits, targets): \n    \n    weights = targets * competition_weights['+'] + (1 - targets) * competition_weights['-']\n    \n    L = torch.zeros(targets.shape, device = DEVICE)\n    \n    w = weights \n    y = targets \n    p = logits \n    eps = 1e-8\n    \n    for i in range(L.shape[0]): \n        for j in range(L.shape[1]): \n            L[i, j] = -w[i, j] * (y[i, j] * math.log(p[i, j] + eps) + (1 - y[i, j]) * math.log(1 - p[i, j] + eps))\n            \n    Exams_Loss = torch.div(torch.sum(L, dim = 1), torch.sum(w, dim = 1))\n    \n    return Exams_Loss","metadata":{"execution":{"iopub.status.busy":"2022-10-03T22:34:49.597028Z","iopub.execute_input":"2022-10-03T22:34:49.597463Z","iopub.status.idle":"2022-10-03T22:34:49.606232Z","shell.execute_reply.started":"2022-10-03T22:34:49.597428Z","shell.execute_reply":"2022-10-03T22:34:49.605273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)\n\ndf = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\n\ninstances = df.StudyInstanceUID.unique().tolist()\ninstances = random.sample(instances, k=int(len(instances)*DF_SIZE))\ndf = df[df[\"StudyInstanceUID\"].isin(instances)].reset_index(drop=True)\nprint(clr.S+\"Dataframe size:\"+clr.E, df.shape)\n\nkfold = GroupKFold(n_splits=N_SPLITS)\ndf['fold'] = -1\n\nfor k, (_, valid_i) in enumerate(kfold.split(df,\n                                             groups=df.StudyInstanceUID)):\n    df.loc[valid_i, 'fold'] = k\n    \nprint(clr.S+\"K Folds Count:\"+clr.E)\ndf[\"fold\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T22:41:33.889726Z","iopub.execute_input":"2022-10-03T22:41:33.890231Z","iopub.status.idle":"2022-10-03T22:41:33.955374Z","shell.execute_reply.started":"2022-10-03T22:41:33.890190Z","shell.execute_reply":"2022-10-03T22:41:33.954329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RSNADataset(Dataset, Randomizable): \n    \n    def __init__(self, csv, mode, transform = None): \n        self.csv = csv \n        self.mode = mode \n        self.transform = transform \n        \n    def __len__(self): \n        return self.csv.shape[0]\n    \n    def randomize(self) -> None: \n        \n        MAX_SEED = np.iinfo(np.uint32).max + 1\n        self.seed = self.R.randint(MAX_SEED, dtype = \"uint32\")\n        \n    def __getitem__(self, index): \n        self.randomize()\n        \n        dt = self.csv.iloc[index, :]\n        study_paths = glob(f\"../input/rsna-fracture-detection/zip_png_images/{dt.StudyInstanceUID}/*\")\n        study_paths.sort(key = natural_keys)\n        \n        study_images = [cv2.imread(path)[:,:,::-1] for path in study_paths]\n        stacked_image = np.stack([img.astype(np.float32) for img in study_images], axis = 2).transpose(3,0,1,2)\n        \n        if self.transform: \n            if isinstance(self.transform, Randomizable): \n                self.transform.set_random_state(seed = self.seed)\n                \n            stacked_image = apply_transform(self.transform, stacked_image)\n            \n        if self.mode == \"test\": \n            return{\"image\" : stacked_image}\n        else: \n            targets = torch.tensor(dt[target_cols]).float()\n            return {\"image\" : stacked_image, \"targets\" : targets}","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:06:09.234252Z","iopub.execute_input":"2022-10-03T23:06:09.235217Z","iopub.status.idle":"2022-10-03T23:06:09.247646Z","shell.execute_reply.started":"2022-10-03T23:06:09.235170Z","shell.execute_reply":"2022-10-03T23:06:09.246504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_to_device(data): \n    image, targets = data.values()\n    return image.to(DEVICE), targets.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:06:12.912635Z","iopub.execute_input":"2022-10-03T23:06:12.913490Z","iopub.status.idle":"2022-10-03T23:06:12.919764Z","shell.execute_reply.started":"2022-10-03T23:06:12.913445Z","shell.execute_reply":"2022-10-03T23:06:12.918402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = Compose([ScaleIntensity(), Resize((IMG_RESIZE, IMG_RESIZE, STACK_RESIZE)), ToTensor()])\nvalid_transforms = Compose([ScaleIntensity(), Resize((IMG_RESIZE, IMG_RESIZE, STACK_RESIZE)), ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:06:14.560299Z","iopub.execute_input":"2022-10-03T23:06:14.560765Z","iopub.status.idle":"2022-10-03T23:06:14.568494Z","shell.execute_reply.started":"2022-10-03T23:06:14.560709Z","shell.execute_reply":"2022-10-03T23:06:14.567097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = df.head(6)\n\ndataset = RSNADataset(csv = sample_df, mode = \"train\", transform = train_transforms)\ndataloader = DataLoader(dataset, batch_size = 3, shuffle = False)\n\nfor k, data in enumerate(dataloader): \n    image, targets = data_to_device(data)\n    print(clr.S + f\"Batch: {k}\" + clr.E, \"\\n\" + \n          clr.S + \"Image:\" + clr.E, image.shape, \"\\n\" + \n          clr.S + \"Targets:\" + clr.E, targets, \"\\n\"+ \n          \"=\"*50)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:06:16.302814Z","iopub.execute_input":"2022-10-03T23:06:16.304053Z","iopub.status.idle":"2022-10-03T23:07:35.231452Z","shell.execute_reply.started":"2022-10-03T23:06:16.303991Z","shell.execute_reply":"2022-10-03T23:07:35.230236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del dataset, dataloader, image, targets \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:09:42.512930Z","iopub.execute_input":"2022-10-03T23:09:42.513443Z","iopub.status.idle":"2022-10-03T23:09:42.550898Z","shell.execute_reply.started":"2022-10-03T23:09:42.513403Z","shell.execute_reply":"2022-10-03T23:09:42.548005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CRITERION = nn.BCEWithLogitsLoss(reduction = 'none')\n\ndef get_criterion(logits, target): \n    loss = CRITERION(logits.view(-1), target.view(-1))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:13:08.395195Z","iopub.execute_input":"2022-10-03T23:13:08.395767Z","iopub.status.idle":"2022-10-03T23:13:08.403307Z","shell.execute_reply.started":"2022-10-03T23:13:08.395707Z","shell.execute_reply":"2022-10-03T23:13:08.401967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n   \n    \n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, \n                                                       total_epoch, after_scheduler)\n    \n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier \n                                                     for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier \n                    for base_lr in self.base_lrs]\n        \n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) \n                    for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) \n                    for base_lr in self.base_lrs]\n","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:14:47.956028Z","iopub.execute_input":"2022-10-03T23:14:47.956533Z","iopub.status.idle":"2022-10-03T23:14:47.968016Z","shell.execute_reply.started":"2022-10-03T23:14:47.956493Z","shell.execute_reply":"2022-10-03T23:14:47.966755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_in_file(text, f): \n    with open(f'log_{KERNEL_TYPE}.txt', 'a+') as f: \n        print(text, file = f)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:15:59.735179Z","iopub.execute_input":"2022-10-03T23:15:59.735667Z","iopub.status.idle":"2022-10-03T23:15:59.742521Z","shell.execute_reply.started":"2022-10-03T23:15:59.735617Z","shell.execute_reply":"2022-10-03T23:15:59.741115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, epoch, f):\n    \n    \n    print(\"Training...\")\n    add_in_file('Training...', f)\n    \n   \n    start_time = time()\n    \n   \n    model.train()\n    train_losses, train_comp_losses = [], []\n    \n   \n    bar = tqdm(dataloader)\n    for data in bar:\n        image, targets = data_to_device(data)\n        \n      \n        optimizer.zero_grad()\n        logits = model(image)\n        loss = get_criterion(logits, targets)\n        loss.sum().backward()\n        optimizer.step()\n        \n   \n        comp_loss = get_custom_loss(logits, targets)\n\n       \n        train_losses.append(loss.detach().cpu().numpy())\n        train_comp_losses.append(comp_loss.detach().cpu().numpy().mean())\n        \n        gc.collect()\n\n  \n    mean_train_loss = np.mean(train_losses)\n    mean_comp_loss = np.mean(train_comp_losses)\n    \n    total_time = round((time() - start_time)/60, 3)\n    add_in_file('Train Mean Loss: {}'.format(mean_train_loss), f)\n    add_in_file('Train Mean Comp Loss: {}'.format(mean_comp_loss), f)\n    add_in_file('~~~ Train Time: {} mins ~~~'.format(total_time), f)\n    \n   \n    wandb.log({\"train_loss\": mean_train_loss,\n               \"train_comp_loss\": mean_comp_loss,}, step=epoch)\n                \n  \n    print(clr.S+\"Train Mean Loss:\"+clr.E, mean_train_loss)\n    print(clr.S+\"Train Mean Comp Loss:\"+clr.E, mean_comp_loss)\n    print(clr.S+f\"~~~ Train Time: {total_time} mins ~~~\"+clr.E)\n    \n    return mean_train_loss","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:17:13.329809Z","iopub.execute_input":"2022-10-03T23:17:13.330289Z","iopub.status.idle":"2022-10-03T23:17:13.343969Z","shell.execute_reply.started":"2022-10-03T23:17:13.330250Z","shell.execute_reply":"2022-10-03T23:17:13.342936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_epoch(model, dataloader, epoch, f):\n    \n   \n    print(\"Validation...\")\n    add_in_file('Validation...', f)\n    \n   \n    start_time = time()\n    \n    \n    model.eval()\n    valid_preds, valid_targets, valid_comp_loss = [], [], []\n    \n    with torch.no_grad():\n        for data in dataloader:\n            \n            image, targets = data_to_device(data)\n            logits = model(image)\n            \n            comp_loss = get_custom_loss(logits, targets)\n          \n            valid_targets.append(targets.detach().cpu())\n            valid_preds.append(logits.detach().cpu())\n            valid_comp_loss.append(comp_loss.detach().cpu().numpy().mean())\n            \n            gc.collect()\n\n    valid_losses = get_criterion(torch.cat(valid_preds), torch.cat(valid_targets)).numpy()\n    mean_valid_loss = np.mean(valid_losses)\n    \n    mean_comp_valid_loss = np.mean(valid_comp_loss)\n    \n    PREDS = np.concatenate(torch.cat(valid_preds).numpy())\n    TARGETS = np.concatenate(torch.cat(valid_targets).numpy())\n    auc = roc_auc_score(TARGETS, PREDS)\n\n    total_time = round((time() - start_time)/60, 3)\n    add_in_file('Valid Mean Loss: {}'.format(mean_valid_loss), f)\n    add_in_file('Valid Mean Comp Loss: {}'.format(mean_comp_valid_loss), f)\n    add_in_file('Valid AUC: {}'.format(auc), f)\n    add_in_file('~~~ Valid Time: {} mins ~~~'.format(total_time), f)\n    \n    wandb.log({\"valid_loss\": mean_valid_loss,\n               \"valid_comp_loss\": mean_comp_valid_loss,\n               \"valid_auc\": auc}, step=epoch)\n     \n    print(clr.S+\"Valid Mean Loss:\"+clr.E, mean_valid_loss)\n    print(clr.S+\"Valid Mean Comp Loss:\"+clr.E, mean_comp_valid_loss)\n    print(clr.S+\"Valid AUC:\"+clr.E, auc)\n    print(clr.S+f\"~~~ Validation Time: {total_time} mins ~~~\"+clr.E)\n    \n    return mean_valid_loss","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:18:03.121875Z","iopub.execute_input":"2022-10-03T23:18:03.122326Z","iopub.status.idle":"2022-10-03T23:18:03.136974Z","shell.execute_reply.started":"2022-10-03T23:18:03.122291Z","shell.execute_reply":"2022-10-03T23:18:03.135779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_train(fold):\n    \n  \n    RUN_CONFIG = CONFIG.copy()\n    params = dict(model=\"densenet121\", \n                  epochs=EPOCHS, \n                  split=N_SPLITS, \n                  batch=BATCH_SIZE, lr=LR,\n                  img_size=IMG_RESIZE, stack_size=STACK_RESIZE,\n                  data_size=DF_SIZE)\n    RUN_CONFIG.update(params)\n    run = wandb.init(project='RSNA_SpineFructure', config=CONFIG)\n    \n   \n    train = df[df[\"fold\"] != fold].reset_index(drop=True)\n    valid = df[df[\"fold\"] == fold].reset_index(drop=True)\n    \n    \n    train_dataset = RSNADataset(csv=train, mode=\"train\", \n                                transform=train_transforms)\n    valid_dataset = RSNADataset(csv=valid, mode=\"train\", \n                                transform=valid_transforms)\n    \n    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                             sampler=RandomSampler(train_dataset))\n    validloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n    \n\n    model = densenet.densenet121(spatial_dims=3, in_channels=3,\n                                 out_channels=OUT_DIM)\n    model.class_layers.out = nn.Sequential(nn.Linear(in_features=1024, out_features=OUT_DIM), \n                                           nn.Softmax(dim=1))\n    model.to(DEVICE)\n    wandb.watch(model, log_freq=100) # 🐝\n    \n  \n    optimizer = optim.Adam(model.parameters(), lr=LR)\n    scheduler_cosine = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 2)\n    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, \n                                                total_epoch=1, \n                                                after_scheduler=scheduler_cosine)\n    \n   \n    valid_loss_BEST = 1000\n  \n    model_file = f'{KERNEL_TYPE}_best_fold{fold}.pth'\n   \n    f = open(f'log_{KERNEL_TYPE}.txt', 'a')\n    \n    \n    for epoch in range(EPOCHS):\n        \n        add_in_file('======== Epoch: {}/{} ========'.format(epoch+1, EPOCHS), f)\n        print(\"=\"*8, clr.S+f\"Epoch {epoch}\"+clr.E, \"=\"*8)\n        \n        scheduler_warmup.step(epoch-1)\n    \n       \n        mean_train_loss = train_epoch(model, trainloader, optimizer, epoch, f)\n        mean_valid_loss = valid_epoch(model, validloader, epoch, f)\n        \n    \n        if mean_valid_loss < valid_loss_BEST:\n            print('Saving model ...')\n            add_in_file('Saving model => {}'.format(model_file), f)\n            torch.save(model.state_dict(), model_file)\n            valid_loss_BEST = mean_valid_loss\n            \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n  \n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:19:17.803912Z","iopub.execute_input":"2022-10-03T23:19:17.804406Z","iopub.status.idle":"2022-10-03T23:19:17.823790Z","shell.execute_reply.started":"2022-10-03T23:19:17.804366Z","shell.execute_reply":"2022-10-03T23:19:17.822083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_train(fold=0)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T23:20:13.480425Z","iopub.execute_input":"2022-10-03T23:20:13.480894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open('../input/rsna-fracture-detection/log_densenet121_baseline.txt', 'r')\nprint(f.read())\nf.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_dataset_artifact(run_name=\"save_logs\", artifact_name=\"logs\",\n                      path=\"../input/rsna-fracture-detection/log_densenet121_baseline.txt\", data_type=\"dataset\")\nsave_dataset_artifact(run_name=\"save_model\", artifact_name=\"model\",\n                      path=\"../input/rsna-fracture-detection/densenet121_baseline_best_fold0.pth\", data_type=\"model\")","metadata":{},"execution_count":null,"outputs":[]}]}